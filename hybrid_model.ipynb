{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((14,14)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 使用单个值进行归一化\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-100 训练集\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "\n",
    "# 定义想要的类别\n",
    "filtered_classes = ['bear', 'tiger']\n",
    "\n",
    "# 获取类别到索引的映射\n",
    "class_to_idx = trainset.class_to_idx\n",
    "\n",
    "# 筛选出对应索引\n",
    "filtered_class_indices = [class_to_idx[cls] for cls in filtered_classes]\n",
    "\n",
    "# 过滤数据集\n",
    "filtered_trainset = [data for data in trainset if data[1] in filtered_class_indices]\n",
    "\n",
    "# 过滤数据集并修改标签\n",
    "filtered_trainset = []\n",
    "for data, label in trainset:\n",
    "    if label in filtered_class_indices:\n",
    "        # 将 'bear' 的标签设置为 0，'tiger' 的标签设置为 1\n",
    "        new_label = 0 if label == filtered_class_indices[0] else 1\n",
    "        filtered_trainset.append((data, new_label))\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = int(0.8 * len(filtered_trainset))\n",
    "validation_size = len(filtered_trainset) - train_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(filtered_trainset, [train_size, validation_size])\n",
    "\n",
    "print(train_size)\n",
    "print(validation_size)\n",
    "# 创建 DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(validation_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "train_num = train_size\n",
    "val_num = validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_class_indices)\n",
    "print(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 获取一个批次的数据\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# 设置图像显示的行数和列数\n",
    "rows = 2\n",
    "cols = 2\n",
    "\n",
    "# 创建一个图形和一组子图\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "# 遍历所有图像\n",
    "for i in range(rows*cols):\n",
    "    image = images[i].numpy() # 转换为 numpy 数组\n",
    "    image = np.transpose(image, (1, 2, 0)) # 调整通道顺序\n",
    "    print(image.shape)\n",
    "    # 显示图像\n",
    "    ax = axes[i//cols, i%cols]\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off') # 关闭坐标轴\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title hybrid layer\n",
    "# !pip install pennylane\n",
    "!pip install pennylane==0.23.0\n",
    "# !pip install pennylane\n",
    "# !pip uninstall autoray\n",
    "!pip install autoray==0.2.5\n",
    "# !pip install pennylane-qulacs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from math import ceil\n",
    "from math import pi\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_qubits = 4\n",
    "n_layers = 1\n",
    "n_class = 2\n",
    "n_features = 196\n",
    "image_x_y_dim = 14\n",
    "kernel_size = n_qubits\n",
    "stride = 2\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "\n",
    "def circuit(inputs, weights):\n",
    "    var_per_qubit = int(len(inputs) / n_qubits) + 1\n",
    "    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit / 2)\n",
    "    for qub in range(n_qubits):\n",
    "        qml.Hadamard(wires=qub)\n",
    "        for i in range(var_per_qubit):\n",
    "            if (qub * var_per_qubit + i) < len(inputs):\n",
    "                exec('qml.{}({}, wires = {})'.format(encoding_gates[i], inputs[qub * var_per_qubit + i], qub))\n",
    "            else:  # load nothing\n",
    "                pass\n",
    "\n",
    "    for l in range(n_layers):\n",
    "        for i in range(n_qubits):\n",
    "            qml.CRZ(weights[l, i], wires=[i, (i + 1) % n_qubits])\n",
    "            # qml.CNOT(wires = [i, (i + 1) % n_qubits])\n",
    "        for j in range(n_qubits, 2 * n_qubits):\n",
    "            qml.RY(weights[l, j], wires=j % n_qubits)\n",
    "\n",
    "    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    return _expectations\n",
    "    # return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "class Quanv2d(nn.Module):\n",
    "    def __init__(self, kernel_size=None, stride=None):\n",
    "        super(Quanv2d, self).__init__()\n",
    "        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n",
    "        qnode = qml.QNode(circuit, dev, interface='torch', diff_method='best')\n",
    "        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        assert len(X.shape) == 4\n",
    "        bs = X.shape[0]\n",
    "        XL = []\n",
    "        for i in range(0, X.shape[2] - 2, stride):\n",
    "            for j in range(0, X.shape[3] - 2, stride):\n",
    "                XL.append(self.ql1(torch.flatten(X[:, :, i:i + kernel_size, j:j + kernel_size], start_dim=1)))\n",
    "        X = torch.cat(XL, dim=1).view(bs,4,6,6)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.ql1 = Quanv2d(kernel_size=kernel_size, stride=stride)\n",
    "        self.conv1 = nn.Conv2d(4,16,3,stride=1)\n",
    "        self.fc1 = nn.Linear(16*4*4, n_class * 2)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.fc2 = nn.Linear(n_class * 2, n_class)\n",
    "\n",
    "    def forward(self, X):\n",
    "        bs = X.shape[0]\n",
    "        X = X.view(bs, 1, image_x_y_dim, image_x_y_dim)\n",
    "        X = self.ql1(X)\n",
    "        X = self.lr1(self.conv1(X))\n",
    "        X = X.view(bs,-1)\n",
    "        X = self.fc1(X)\n",
    "        X = self.lr1(X)\n",
    "        X = self.fc2(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "kernel_size=2\n",
    "\n",
    "\n",
    "def circuit(inputs, weights):\n",
    "    var_per_qubit = int(len(inputs) / n_qubits) + 1\n",
    "    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit / 2)\n",
    "\n",
    "    for qub in range(n_qubits):\n",
    "        qml.Hadamard(wires=qub)\n",
    "        for i in range(var_per_qubit):\n",
    "            idx = qub * var_per_qubit + i\n",
    "            if idx < len(inputs):\n",
    "                if encoding_gates[i] == 'RZ':\n",
    "                    qml.RZ(inputs[idx], wires=qub)\n",
    "                elif encoding_gates[i] == 'RY':\n",
    "                    qml.RY(inputs[idx], wires=qub)\n",
    "\n",
    "    for l in range(n_layers):\n",
    "        for i in range(n_qubits):\n",
    "            qml.CRZ(weights[l, i], wires=[i, (i + 1) % n_qubits])\n",
    "        for j in range(n_qubits, 2 * n_qubits):\n",
    "            qml.RY(weights[l, j], wires=j % n_qubits)\n",
    "\n",
    "    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "    return _expectations\n",
    "\n",
    "class Quanv2d(nn.Module):\n",
    "    def __init__(self, kernel_size=None, stride=None):\n",
    "        super(Quanv2d, self).__init__()\n",
    "        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n",
    "        qnode = qml.QNode(circuit, dev, interface='torch', diff_method='best')\n",
    "        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, X):\n",
    "        assert len(X.shape) == 4\n",
    "        bs = X.shape[0]\n",
    "        XL = []\n",
    "        for i in range(0, X.shape[2] - 2, stride):\n",
    "            for j in range(0, X.shape[3] - 2, stride):\n",
    "                XL.append(self.ql1(torch.flatten(X[:, :, i:i + kernel_size, j:j + kernel_size], start_dim=1)))\n",
    "        X = torch.cat(XL, dim=1).view(bs,4,6,6)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.ql1 = Quanv2d(kernel_size=kernel_size, stride=stride)\n",
    "        self.conv1 = nn.Conv2d(4,16,3,stride=1)\n",
    "        self.fc1 = nn.Linear(16*4*4, n_class * 2)\n",
    "        self.lr1 = nn.LeakyReLU(0.1)\n",
    "        self.fc2 = nn.Linear(n_class * 2, n_class)\n",
    "\n",
    "    def forward(self, X):\n",
    "        bs = X.shape[0]\n",
    "        X = X.view(bs, 1, image_x_y_dim, image_x_y_dim)\n",
    "        X = self.ql1(X) #output(bs, 4, 6, 6)\n",
    "        X = self.lr1(self.conv1(X))\n",
    "        X = X.view(bs,-1)\n",
    "        X = self.fc1(X)\n",
    "        X = self.lr1(X)\n",
    "        X = self.fc2(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 20\n",
    "    train_num = len(trainloader)\n",
    "    # val_num = len(validate_dataset)\n",
    "\n",
    "\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "\n",
    "\n",
    "\n",
    "    net = Net()\n",
    "    # net =SimpleNet()\n",
    "    net.to(device)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    # pata = list(net.parameters())\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "    epochs = 5\n",
    "    # save_path = './AlexNet.pth'\n",
    "    best_acc = 0.0\n",
    "    train_steps = len(trainloader)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(trainloader, file=sys.stdout)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            print(images.shape)\n",
    "            print(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images.to(device))\n",
    "            loss = loss_function(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,\n",
    "                                                                     epochs,\n",
    "                                                                     loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validationloader, file=sys.stdout)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        # if val_accurate > best_acc:\n",
    "        #     best_acc = val_accurate\n",
    "        #     torch.save(net.state_dict(), save_path)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
